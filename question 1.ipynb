{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#Apply PCA on CC General data set\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the dataset\ncc_data = pd.read_csv('CC GENERAL.csv')\n\n# Drop the categorical columns and ID column if present\ncc_data = cc_data.drop(['CUST_ID', 'TENURE'], axis=1)\n\n# Fill any missing values with mean of respective column\ncc_data = cc_data.fillna(cc_data.mean())\n\n# Scale the data using StandardScaler\nscaler = StandardScaler()\ncc_scaled = scaler.fit_transform(cc_data)\n\n# Initialize PCA model with 2 components\npca = PCA(n_components=2)\n\n# Fit and transform the data using PCA\ncc_pca = pca.fit_transform(cc_scaled)\n\n# Print the explained variance ratio\nprint('Explained variance ratio:', pca.explained_variance_ratio_)\n\n# Create a new dataframe with the transformed data\ncc_pca_df = pd.DataFrame(data=cc_pca, columns=['PC1', 'PC2'])\n\n# Print the transformed data\nprint('Transformed data:', cc_pca_df.head())\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "Explained variance ratio: [0.28845814 0.21570572]\nTransformed data:         PC1       PC2\n0 -1.718893 -1.072943\n1 -1.169300  2.509347\n2  0.938412 -0.382610\n3 -0.907499  0.045867\n4 -1.637831 -0.684985\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#Calculate silhouette score without applying pca\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Load the dataset\ncc_data = pd.read_csv('CC GENERAL.csv')\n\n# Drop the categorical columns and ID column if present\ncc_data = cc_data.drop(['CUST_ID', 'TENURE'], axis=1)\n\n# Fill any missing values with mean of respective column\ncc_data = cc_data.fillna(cc_data.mean())\n\n# Scale the data using StandardScaler\nscaler = StandardScaler()\ncc_scaled = scaler.fit_transform(cc_data)\n\n# Initialize k-means model with 2 clusters\nkmeans = KMeans(n_clusters=2)\n\n# Fit the k-means model on the scaled data\nkmeans.fit(cc_scaled)\n\n# Calculate the silhouette score of the clustered data\nsilhouette_avg = silhouette_score(cc_scaled, kmeans.labels_)\n\n# Print the silhouette score\nprint('Silhouette score:', silhouette_avg)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "text": "Silhouette score: 0.2258949806035794\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#Calculate silhouette score applying pca\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the dataset\ncc_data = pd.read_csv('CC GENERAL.csv')\n\n# Drop the categorical columns and ID column if present\ncc_data = cc_data.drop(['CUST_ID', 'TENURE'], axis=1)\n\n# Fill any missing values with mean of respective column\ncc_data = cc_data.fillna(cc_data.mean())\n\n# Scale the data using StandardScaler\nscaler = StandardScaler()\ncc_scaled = scaler.fit_transform(cc_data)\n\n# Initialize PCA model with 2 components\npca = PCA(n_components=2)\n\n# Fit and transform the data using PCA\ncc_pca = pca.fit_transform(cc_scaled)\n\n# Initialize k-means model with 2 clusters\nkmeans = KMeans(n_clusters=2)\n\n# Fit the k-means model on the PCA transformed data\nkmeans.fit(cc_pca)\n\n# Calculate the silhouette score of the clustered data\nsilhouette_avg = silhouette_score(cc_pca, kmeans.labels_)\n\n# Print the silhouette score\nprint('Silhouette score:', silhouette_avg)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": "Silhouette score: 0.46264255199648574\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#Perform Scaling+PCA+K-Means and report performance with 2 clusters in kmeans\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Load the dataset\ncc_data = pd.read_csv('CC GENERAL.csv')\n\n# Drop the categorical columns and ID column if present\ncc_data = cc_data.drop(['CUST_ID', 'TENURE'], axis=1)\n\n# Fill any missing values with mean of respective column\ncc_data = cc_data.fillna(cc_data.mean())\n\n# Scale the data using StandardScaler\nscaler = StandardScaler()\ncc_scaled = scaler.fit_transform(cc_data)\n\n# Apply PCA\npca = PCA(n_components=2)\ncc_pca = pca.fit_transform(cc_scaled)\n\n# Initialize k-means model with 2 clusters\nkmeans = KMeans(n_clusters=2)\n\n# Fit the k-means model on the PCA data\nkmeans.fit(cc_pca)\n\n# Calculate the silhouette score of the clustered data\nsilhouette_avg = silhouette_score(cc_pca, kmeans.labels_)\n\n# Print the silhouette score\nprint('Silhouette score:', silhouette_avg)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "text": "Silhouette score: 0.4662268823892948\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#Perform Scaling+PCA+K-Means and report performance with 3 clusters in kmeans\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Load the dataset\ncc_data = pd.read_csv('CC GENERAL.csv')\n\n# Drop the categorical columns and ID column if present\ncc_data = cc_data.drop(['CUST_ID', 'TENURE'], axis=1)\n\n# Fill any missing values with mean of respective column\ncc_data = cc_data.fillna(cc_data.mean())\n\n# Scale the data using StandardScaler\nscaler = StandardScaler()\ncc_scaled = scaler.fit_transform(cc_data)\n\n# Apply PCA\npca = PCA(n_components=2)\ncc_pca = pca.fit_transform(cc_scaled)\n\n# Initialize k-means model with 3 clusters\nkmeans = KMeans(n_clusters=3, random_state=42)\n\n# Fit the k-means model on the PCA data\nkmeans.fit(cc_pca)\n\n# Calculate the silhouette score of the clustered data\nsilhouette_avg = silhouette_score(cc_pca, kmeans.labels_)\n\n# Print the silhouette score\nprint('Silhouette score:', silhouette_avg)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": "Silhouette score: 0.4533203497133842\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}